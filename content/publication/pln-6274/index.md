---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: Cross-lingual Training for Multiple-Choice Question Answering
subtitle: ''
summary: ''
authors:
- Guillermo Echegoyen y Álvaro Rodrigo y Anselmo Peñas
tags:
- '""'
categories: []
date: '2020-01-01'
lastmod: 2020-09-16T16:30:04+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2020-09-16T14:30:04.093897Z'
publication_types:
- 2
abstract: In this work we explore to what extent multilingual models can be trained
  for one language and applied to a different one for the task of Multiple Choice
  Question Answering. We employ the RACE dataset to fine-tune both a monolingual and
  a multilingual models and apply these models to another different collections in
  different languages. The results show that both monolingual and multilingual models
  can be zero-shot transferred to a different dataset in the same language maintaining
  its performance. Besides, the multilingual model still performs good when it is
  applied to a different target language. Additionally, we find that exams that are
  more difficult to humans are harder for machines too. Finally, we advance the state-of-the-art
  for the QA4MRE Entrance Exams dataset in several languages.
publication: '*Procesamiento del Lenguaje Natural*'
url_pdf: http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6274
---
